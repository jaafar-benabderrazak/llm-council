"""Main LLM Council orchestrator."""
import sys
import os
from typing import List, Optional, Dict
from dataclasses import dataclass, asdict
import json
from datetime import datetime

# Fix Windows console encoding issues with Rich
if sys.platform == "win32":
    os.environ["PYTHONIOENCODING"] = "utf-8"

from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.progress import Progress, SpinnerColumn, TextColumn

from agents import BaseAgent, AgentResponse
from config import Config


@dataclass
class DebateResult:
    """Results from a council debate."""
    topic: str
    rounds: List[List[AgentResponse]]
    synthesis: str
    timestamp: str
    total_tokens: int
    participating_agents: List[str]
    
    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "topic": self.topic,
            "timestamp": self.timestamp,
            "total_tokens": self.total_tokens,
            "participating_agents": self.participating_agents,
            "rounds": [
                [
                    {
                        "agent_name": resp.agent_name,
                        "model": resp.model,
                        "content": resp.content,
                        "tokens_used": resp.tokens_used,
                        "metadata": resp.metadata
                    }
                    for resp in round_responses
                ]
                for round_responses in self.rounds
            ],
            "synthesis": self.synthesis
        }
    
    def save_to_file(self, filename: Optional[str] = None):
        """Save debate results to JSON file."""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"debate_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)
        
        return filename
    
    def save_to_markdown(self, filename: Optional[str] = None, results_only: bool = False) -> str:
        """
        Save debate results as a comprehensive Markdown article.
        
        Args:
            filename: Optional custom filename (without extension)
            results_only: If True, generate results-focused document without discussions
            
        Returns:
            Path to the saved Markdown file
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            prefix = "results_" if results_only else "article_"
            filename = f"{prefix}{timestamp}.md"
        elif not filename.endswith('.md'):
            filename = f"{filename}.md"
        
        # Build markdown article
        if results_only:
            markdown_content = self._build_results_document()
        else:
            markdown_content = self._build_markdown_article()
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        return filename
    
    def _build_markdown_article(self) -> str:
        """Build a comprehensive Markdown article from the debate."""
        lines = []
        
        # Title and metadata
        lines.append(f"# {self.topic}")
        lines.append("")
        lines.append(f"**Generated by LLM Council** - {self.timestamp}")
        lines.append("")
        lines.append(f"**Participating Agents:** {', '.join(self.participating_agents)}")
        lines.append(f"**Total Tokens:** {self.total_tokens:,}")
        lines.append(f"**Debate Rounds:** {len(self.rounds)}")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Add overview diagram
        lines.append("## Debate Overview")
        lines.append("")
        lines.append("```mermaid")
        lines.append("graph LR")
        lines.append(f"    A[Topic:<br/>{self._truncate(self.topic, 40)}] --> B[Multi-Round<br/>Debate]")
        lines.append("")
        
        # Add agents to diagram
        for i, agent in enumerate(self.participating_agents, 1):
            lines.append(f"    B --> C{i}[{agent}]")
        
        lines.append("")
        lines.append("    " + " & ".join([f"C{i}" for i in range(1, len(self.participating_agents)+1)]) + " --> D[Synthesis]")
        lines.append("    D --> E[Comprehensive<br/>Article]")
        lines.append("")
        lines.append("    style E fill:#90EE90")
        lines.append("```")
        lines.append("")
        
        # Add debate process diagram
        lines.append("## Debate Process")
        lines.append("")
        lines.append("```mermaid")
        lines.append("sequenceDiagram")
        lines.append("    participant User")
        lines.append("    participant Council")
        
        # Add agents as participants
        for agent in self.participating_agents[:3]:  # Limit to 3 for readability
            lines.append(f"    participant {agent}")
        
        lines.append("")
        lines.append(f"    User->>Council: {self._truncate(self.topic, 50)}")
        lines.append("")
        
        # Show rounds
        for round_num in range(min(2, len(self.rounds))):  # Show max 2 rounds for readability
            lines.append(f"    Note over Council: Round {round_num + 1}")
            for agent in self.participating_agents[:3]:
                if round_num == 0:
                    lines.append(f"    Council->>+{agent}: Provide analysis with sources")
                    lines.append(f"    {agent}-->>-Council: Analysis + Citations")
                else:
                    lines.append(f"    Council->>+{agent}: Validate sources & cross-check")
                    lines.append(f"    {agent}-->>-Council: Validation + New evidence")
            lines.append("")
        
        lines.append("    Council->>Council: Generate comprehensive article")
        lines.append("    Council-->>User: Final article with verified sources")
        lines.append("```")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Round summaries
        lines.append("## Debate Rounds Summary")
        lines.append("")
        
        for round_num, round_responses in enumerate(self.rounds, 1):
            lines.append(f"### Round {round_num}: {self._get_round_title(round_num)}")
            lines.append("")
            
            for response in round_responses:
                lines.append(f"#### {response.agent_name}")
                if response.tokens_used:
                    lines.append(f"*Tokens: {response.tokens_used}, Model: {response.model}*")
                lines.append("")
                
                # Add response content (truncated if very long)
                content = response.content
                if len(content) > 2000:
                    lines.append(f"{content[:2000]}...")
                    lines.append("")
                    lines.append(f"*[Response truncated - see full content in JSON file]*")
                else:
                    lines.append(content)
                
                lines.append("")
                lines.append("---")
                lines.append("")
        
        # Comprehensive synthesis (main article)
        lines.append("## Comprehensive Synthesis Article")
        lines.append("")
        lines.append(self.synthesis)
        lines.append("")
        
        # Add statistics diagram
        lines.append("---")
        lines.append("")
        lines.append("## Debate Statistics")
        lines.append("")
        lines.append("```mermaid")
        lines.append("pie title Token Distribution by Agent")
        
        # Calculate token distribution
        for agent_name in self.participating_agents:
            agent_tokens = sum(
                resp.tokens_used or 0 
                for round_responses in self.rounds 
                for resp in round_responses 
                if resp.agent_name == agent_name
            )
            lines.append(f'    "{agent_name}" : {agent_tokens}')
        
        lines.append("```")
        lines.append("")
        
        # Add metadata table
        lines.append("| Metric | Value |")
        lines.append("|--------|-------|")
        lines.append(f"| Total Rounds | {len(self.rounds)} |")
        lines.append(f"| Total Agents | {len(self.participating_agents)} |")
        lines.append(f"| Total Tokens | {self.total_tokens:,} |")
        lines.append(f"| Avg Tokens/Round | {self.total_tokens // len(self.rounds):,} |")
        
        # Count total responses
        total_responses = sum(len(round_responses) for round_responses in self.rounds)
        lines.append(f"| Total Responses | {total_responses} |")
        lines.append(f"| Avg Tokens/Response | {self.total_tokens // total_responses:,} |")
        lines.append("")
        
        # Footer
        lines.append("---")
        lines.append("")
        lines.append("*Generated by [LLM Council](https://github.com/jaafar-benabderrazak/llm-council) - Multi-Agent AI Research Framework*")
        lines.append("")
        lines.append("**Research Mode Features:**")
        lines.append("- âœ… Source citations and validation")
        lines.append("- âœ… Multi-agent cross-checking")
        lines.append("- âœ… Common misconceptions addressed")
        lines.append("- âœ… Technical depth and specifications")
        lines.append("- âœ… Verified references with credibility ratings")
        lines.append("")
        
        return "\n".join(lines)
    
    def _truncate(self, text: str, max_length: int) -> str:
        """Truncate text for diagram labels."""
        text = text.strip().replace("\n", " ")
        if len(text) <= max_length:
            return text
        return text[:max_length-3] + "..."
    
    def _build_results_document(self) -> str:
        """
        Build a results-focused document with design patterns, recommendations,
        and best practices - WITHOUT the round-by-round discussions.
        """
        lines = []
        
        # Title and metadata
        lines.append(f"# {self.topic}")
        lines.append("")
        lines.append("## ðŸ“‹ Research Document")
        lines.append("")
        lines.append(f"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**Analysis by**: {', '.join(self.participating_agents)}")
        lines.append(f"**Research Depth**: {len(self.rounds)} rounds of multi-agent analysis")
        lines.append(f"**Total Analysis**: {self.total_tokens:,} tokens")
        lines.append("**Cost**: $0.00 (100% FREE with open-source models)")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Document Purpose
        lines.append("## ðŸŽ¯ Document Purpose")
        lines.append("")
        lines.append("This document presents **synthesized research results** including:")
        lines.append("- ðŸ—ï¸ **Design Patterns** - Proven architectural solutions")
        lines.append("- ðŸ’¡ **Recommendations** - Expert-validated best practices")
        lines.append("- ðŸ”§ **Technical Specifications** - Implementation details")
        lines.append("- ðŸ“š **Verified Sources** - Cross-validated references")
        lines.append("- âš ï¸ **Common Pitfalls** - Misconceptions and how to avoid them")
        lines.append("- ðŸš€ **Action Plan** - Step-by-step implementation guide")
        lines.append("")
        lines.append("*This document focuses on actionable insights. Detailed debates are excluded for clarity.*")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Parse synthesis into structured sections
        synthesis_text = self.synthesis
        
        # Extract sections based on keywords
        sections = self._parse_synthesis_sections(synthesis_text)
        
        # Add Executive Summary
        if "EXECUTIVE SUMMARY" in sections or "SUMMARY" in sections:
            lines.append("## ðŸ“Š Executive Summary")
            lines.append("")
            content = sections.get("EXECUTIVE SUMMARY", sections.get("SUMMARY", ""))
            lines.append(content.strip())
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Introduction/Context
        if "INTRODUCTION" in sections:
            lines.append("## ðŸ“– Introduction & Context")
            lines.append("")
            lines.append(sections["INTRODUCTION"].strip())
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Design Patterns (key section)
        if any(keyword in synthesis_text.upper() for keyword in ["PATTERN", "ARCHITECTURE", "DESIGN"]):
            lines.append("## ðŸ—ï¸ Design Patterns & Architecture")
            lines.append("")
            
            # Extract pattern-related content
            if "TECHNICAL" in sections:
                lines.append(sections["TECHNICAL"].strip())
            elif "ANALYSIS" in sections or "DETAILED ANALYSIS" in sections:
                content = sections.get("DETAILED ANALYSIS", sections.get("ANALYSIS", ""))
                lines.append(content.strip())
            else:
                # Extract from synthesis
                pattern_lines = []
                in_pattern_section = False
                for line in synthesis_text.split('\n'):
                    if any(keyword in line.upper() for keyword in ["PATTERN", "ARCHITECTURE", "DESIGN", "IMPLEMENTATION"]):
                        in_pattern_section = True
                    if in_pattern_section:
                        pattern_lines.append(line)
                        if len(pattern_lines) > 50:  # Reasonable limit
                            break
                if pattern_lines:
                    lines.append('\n'.join(pattern_lines).strip())
            
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Technical Specifications
        if "TECHNICAL" in sections or "DEEP DIVE" in sections:
            lines.append("## ðŸ”§ Technical Specifications")
            lines.append("")
            content = sections.get("TECHNICAL", sections.get("DEEP DIVE", ""))
            lines.append(content.strip())
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Best Practices & Recommendations
        if "BEST PRACTICES" in sections or "RECOMMENDATIONS" in sections:
            lines.append("## ðŸ’¡ Best Practices & Recommendations")
            lines.append("")
            content = sections.get("BEST PRACTICES", sections.get("RECOMMENDATIONS", ""))
            lines.append(content.strip())
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Verified Sources
        if "SOURCE VALIDATION" in sections or "REFERENCES" in sections:
            lines.append("## ðŸ“š Verified Sources & References")
            lines.append("")
            content = sections.get("SOURCE VALIDATION", sections.get("REFERENCES", ""))
            lines.append(content.strip())
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Common Misconceptions
        if "MISCONCEPTIONS" in sections or "COMMON MISCONCEPTIONS" in sections:
            lines.append("## âš ï¸ Common Pitfalls & Misconceptions")
            lines.append("")
            content = sections.get("COMMON MISCONCEPTIONS", sections.get("MISCONCEPTIONS", ""))
            lines.append(content.strip())
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Implementation Guide
        if "IMPLEMENTATION" in sections or "PRACTICAL" in sections:
            lines.append("## ðŸš€ Implementation Guide")
            lines.append("")
            content = sections.get("IMPLEMENTATION", sections.get("PRACTICAL", ""))
            lines.append(content.strip())
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Security/Quality Considerations
        if any(keyword in synthesis_text.upper() for keyword in ["SECURITY", "QUALITY", "PERFORMANCE"]):
            lines.append("## ðŸ”’ Security & Quality Considerations")
            lines.append("")
            # Extract security-related content
            security_content = []
            for section_name, content in sections.items():
                if any(keyword in section_name.upper() for keyword in ["SECURITY", "QUALITY", "PERFORMANCE"]):
                    security_content.append(content.strip())
            if security_content:
                lines.append('\n\n'.join(security_content))
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Conclusion
        if "CONCLUSION" in sections:
            lines.append("## ðŸŽ“ Conclusion & Next Steps")
            lines.append("")
            lines.append(sections["CONCLUSION"].strip())
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # Add Diagrams
        lines.append("## ðŸ“Š Visual Overview")
        lines.append("")
        lines.append("### Solution Architecture")
        lines.append("")
        lines.append("```mermaid")
        lines.append("graph TD")
        lines.append(f"    A[{self._truncate(self.topic, 40)}]")
        lines.append("    A --> B[Design Patterns]")
        lines.append("    A --> C[Best Practices]")
        lines.append("    A --> D[Technical Specs]")
        lines.append("    B --> E[Implementation]")
        lines.append("    C --> E")
        lines.append("    D --> E")
        lines.append("    E --> F[Verified Solution]")
        lines.append("    ")
        lines.append("    style F fill:#90EE90")
        lines.append("    style E fill:#87CEEB")
        lines.append("```")
        lines.append("")
        
        # Add Research Methodology
        lines.append("### Research Methodology")
        lines.append("")
        lines.append("```mermaid")
        lines.append("sequenceDiagram")
        lines.append("    participant Topic")
        lines.append("    participant Agents")
        lines.append("    participant Validation")
        lines.append("    participant Results")
        lines.append("    ")
        lines.append("    Topic->>Agents: Research Question")
        lines.append(f"    Note over Agents: {len(self.participating_agents)} AI models analyze")
        lines.append("    Agents->>Validation: Provide sources")
        lines.append(f"    Note over Validation: {len(self.rounds)} rounds of cross-checking")
        lines.append("    Validation->>Results: Verified insights")
        lines.append("    Results->>Results: Design patterns extracted")
        lines.append("    Results->>Results: Best practices compiled")
        lines.append("```")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Add Analysis Metadata
        lines.append("## ðŸ“‹ Research Metadata")
        lines.append("")
        lines.append("| Metric | Value |")
        lines.append("|--------|-------|")
        lines.append(f"| **Research Team** | {', '.join(self.participating_agents)} |")
        lines.append(f"| **Total Perspectives** | {len(self.participating_agents)} independent AI models |")
        lines.append(f"| **Analysis Rounds** | {len(self.rounds)} rounds of refinement |")
        lines.append(f"| **Total Tokens** | {self.total_tokens:,} |")
        lines.append(f"| **Cost** | $0.00 (FREE with open-source models) |")
        lines.append(f"| **Generated** | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} |")
        lines.append("")
        
        # Add Quality Assurance note
        lines.append("### Quality Assurance")
        lines.append("")
        lines.append("This document was generated through:")
        lines.append(f"- âœ… **{len(self.participating_agents)}** independent AI analyses")
        lines.append(f"- âœ… **{len(self.rounds)}** rounds of cross-validation")
        lines.append("- âœ… **Source verification** across multiple perspectives")
        lines.append("- âœ… **Misconception detection** and correction")
        lines.append("- âœ… **Best practice compilation** from industry standards")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Footer
        lines.append("## ðŸ”— About This Document")
        lines.append("")
        lines.append("**Generated by**: [LLM Council](https://github.com/jaafar-benabderrazak/llm-council)")
        lines.append("**Framework**: Multi-Agent AI Research System")
        lines.append(f"**Models Used**: {', '.join(self.participating_agents)}")
        lines.append("**Document Type**: Results-Focused Research Document")
        lines.append("")
        lines.append("**What's Included:**")
        lines.append("- âœ… Design patterns and architectural solutions")
        lines.append("- âœ… Technical specifications and implementation details")
        lines.append("- âœ… Best practices with verified sources")
        lines.append("- âœ… Common pitfalls and how to avoid them")
        lines.append("- âœ… Actionable recommendations")
        lines.append("")
        lines.append("**What's Excluded:**")
        lines.append("- âŒ Round-by-round debate discussions")
        lines.append("- âŒ Individual agent responses")
        lines.append("- âŒ Back-and-forth exchanges")
        lines.append("")
        lines.append("*For complete debate transcript, see the JSON file or full article.*")
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("*Research conducted with FREE open-source AI models | Zero cost | Multi-perspective validation*")
        
        return "\n".join(lines)
    
    def _parse_synthesis_sections(self, text: str) -> dict:
        """Parse synthesis text into sections based on headers."""
        sections = {}
        current_section = None
        current_content = []
        
        for line in text.split('\n'):
            # Detect section headers (## or **SECTION**)
            if line.startswith('##') or (line.startswith('**') and line.endswith('**') and len(line) > 4):
                # Save previous section
                if current_section:
                    sections[current_section] = '\n'.join(current_content)
                
                # Start new section
                current_section = line.strip('#').strip('*').strip().upper()
                current_content = []
            else:
                current_content.append(line)
        
        # Save last section
        if current_section:
            sections[current_section] = '\n'.join(current_content)
        
        return sections
    
    def _get_round_title(self, round_num: int) -> str:
        """Get descriptive title for round."""
        if round_num == 1:
            return "Initial Analysis with Citations"
        elif round_num == 2:
            return "Source Validation & Cross-Checking"
        elif round_num == 3:
            return "Deep Dive & Refinement"
        else:
            return f"Continued Analysis (Round {round_num})"


class LLMCouncil:
    """Orchestrates multi-agent debates between different LLMs."""
    
    def __init__(self, agents: List[BaseAgent], verbose: bool = True):
        """
        Initialize the LLM Council.
        
        Args:
            agents: List of agents to participate in debates
            verbose: Whether to print progress information
        """
        self.agents = agents
        self.verbose = verbose
        if verbose:
            # Use legacy_windows=False to avoid encoding issues on Windows
            self.console = Console(legacy_windows=False) if sys.platform == "win32" else Console()
        else:
            self.console = None
    
    def debate(
        self, 
        topic: str, 
        rounds: int = 3,
        save_results: bool = True,
        save_markdown: bool = True,
        results_only: bool = True  # NEW: Default to results-only format
    ) -> DebateResult:
        """
        Conduct a multi-round debate on a topic.
        
        Args:
            topic: The topic to debate
            rounds: Number of debate rounds
            save_results: Whether to save results to JSON file
            save_markdown: Whether to save comprehensive article as Markdown
            results_only: If True, generate results-focused document (design patterns, 
                         recommendations, best practices) without discussions.
                         Default: True (automatic results document)
            
        Returns:
            DebateResult containing all responses and synthesis
        """
        if self.verbose:
            self.console.print(Panel.fit(
                f"[bold cyan]LLM Council Debate[/bold cyan]\n\n"
                f"[yellow]Topic:[/yellow] {topic}\n"
                f"[yellow]Rounds:[/yellow] {rounds}\n"
                f"[yellow]Participants:[/yellow] {', '.join([a.name for a in self.agents])}",
                border_style="cyan"
            ))
        
        all_rounds = []
        context = None
        total_tokens = 0
        
        # Conduct debate rounds
        for round_num in range(rounds):
            if self.verbose:
                self.console.print(f"\n[bold green]=== Round {round_num + 1}/{rounds} ===[/bold green]\n")
            
            round_responses = self._conduct_round(topic, context, round_num + 1)
            all_rounds.append(round_responses)
            context = round_responses
            
            # Calculate tokens
            for response in round_responses:
                if response.tokens_used:
                    total_tokens += response.tokens_used
        
        # Generate synthesis
        if self.verbose:
            self.console.print("\n[bold magenta]=== Generating Synthesis ===[/bold magenta]\n")
        
        synthesis = self._generate_synthesis(topic, all_rounds)
        
        # Create result
        result = DebateResult(
            topic=topic,
            rounds=all_rounds,
            synthesis=synthesis,
            timestamp=datetime.now().isoformat(),
            total_tokens=total_tokens,
            participating_agents=[agent.name for agent in self.agents]
        )
        
        # Save if requested
        if save_results:
            json_filename = result.save_to_file()
            if self.verbose:
                self.console.print(f"\n[dim]JSON results saved to: {json_filename}[/dim]")
        
        if save_markdown:
            md_filename = result.save_to_markdown(results_only=results_only)
            if self.verbose:
                doc_type = "Results document" if results_only else "Markdown article"
                self.console.print(f"[dim]{doc_type} saved to: {md_filename}[/dim]")
        
        if self.verbose:
            self.console.print("\n[bold green]Debate Complete![/bold green]")
            self._display_synthesis(synthesis)
        
        return result
    
    def _conduct_round(
        self, 
        topic: str, 
        context: Optional[List[AgentResponse]], 
        round_num: int
    ) -> List[AgentResponse]:
        """Conduct a single debate round with all agents."""
        responses = []
        
        # Build the prompt based on round number
        if round_num == 1:
            prompt = f"""Discuss the following topic and provide your initial perspective with proper citations and sources:

TOPIC: {topic}

Remember to:
- Provide technical depth and specific examples
- Cite authoritative sources (research papers, documentation, official resources)
- Include URLs or proper citations
- Be precise with technical specifications"""
        else:
            prompt = f"""Review the previous responses and provide your critical analysis:

TOPIC: {topic}

Your tasks for Round {round_num}:
- VALIDATE sources provided by other council members
- CROSS-CHECK facts and identify any errors
- CHALLENGE weak arguments with counter-evidence
- BUILD ON strong points with additional sources
- ADDRESS common misconceptions
- PROVIDE new insights with proper citations"""
        
        for agent in self.agents:
            if self.verbose:
                self.console.print(f"[cyan]{agent.name} thinking...[/cyan]")
                response = agent.generate_response(prompt, context, round_num)
                self._display_response(response)
            else:
                response = agent.generate_response(prompt, context, round_num)
            
            responses.append(response)
            
            # Update context for next agent in this round
            if context is None:
                context = [response]
            else:
                context = context + [response]
        
        return responses
    
    def _generate_synthesis(
        self, 
        topic: str, 
        all_rounds: List[List[AgentResponse]]
    ) -> str:
        """Generate a comprehensive academic-style article from all debate rounds."""
        # Use the first agent to synthesize
        synthesizer = self.agents[0]
        
        # Build comprehensive context
        all_responses = []
        for round_num, round_responses in enumerate(all_rounds, 1):
            for response in round_responses:
                all_responses.append(response)
        
        synthesis_prompt = f"""Based on the council's multi-round discussion on: "{topic}"

You must now write a COMPREHENSIVE ACADEMIC-STYLE ARTICLE that:

1. **EXECUTIVE SUMMARY**
   - Brief overview of the topic and key findings
   - Main conclusions (2-3 sentences)

2. **INTRODUCTION**
   - Context and importance of the topic
   - Key questions addressed
   - Scope of the analysis

3. **DETAILED ANALYSIS**
   - Synthesize all perspectives presented
   - Include technical details, specifications, and data points
   - Organize by themes or sub-topics
   - Use headings and subheadings

4. **SOURCE VALIDATION & CROSS-CHECKING**
   - Evaluate the quality and reliability of sources cited
   - List VERIFIED sources (URLs, papers, documentation)
   - Note any conflicting sources or disputed claims
   - Rate source credibility (High/Medium/Low with justification)

5. **CONSENSUS & DISAGREEMENTS**
   - Points of strong agreement across council members
   - Areas of disagreement with competing evidence
   - Nuanced perspectives that warrant consideration

6. **COMMON MISCONCEPTIONS ADDRESSED**
   - Identify and correct common misunderstandings about this topic
   - Explain why these misconceptions are wrong
   - Provide correct information with sources

7. **TECHNICAL DEEP DIVE**
   - Detailed technical specifications, benchmarks, or data
   - Implementation considerations
   - Performance characteristics (if applicable)
   - Trade-offs and limitations

8. **GAPS & LIMITATIONS**
   - What the council couldn't fully address
   - Areas requiring further research
   - Acknowledged uncertainties

9. **ACTIONABLE RECOMMENDATIONS**
   - Concrete, specific recommendations
   - Prioritized by importance and feasibility
   - Context-dependent guidance (when to do X vs Y)

10. **VERIFIED REFERENCES & RESOURCES**
    - Complete list of all cited sources
    - Format: [Title/Description] - [URL or Citation] - [Credibility Rating]
    - Organize by category (Research Papers, Documentation, Tools, etc.)

11. **CONCLUSION**
    - Summary of findings
    - Final verdict or recommendations
    - Future outlook

**FORMAT REQUIREMENTS:**
- Use Markdown formatting with proper headers (##, ###)
- Include bullet points and numbered lists where appropriate
- Make it readable, comprehensive, and academically rigorous
- Minimum 1000 words for complex topics
- Every major claim should reference a source from the debate
- Be thorough, objective, and balanced

Generate the complete article now:"""

        if self.verbose:
            self.console.print("[magenta]Generating comprehensive article with verified sources...[/magenta]")
            synthesis_response = synthesizer.generate_response(
                synthesis_prompt, 
                all_responses,
                round_num=999  # Special round number for synthesis
            )
        else:
            synthesis_response = synthesizer.generate_response(
                synthesis_prompt, 
                all_responses,
                round_num=999
            )
        
        return synthesis_response.content
    
    def _display_response(self, response: AgentResponse):
        """Display an agent response in the console."""
        if not self.verbose:
            return
        
        title = f"[bold]{response.agent_name}[/bold] ({response.model})"
        if response.tokens_used:
            title += f" - {response.tokens_used} tokens"
        
        self.console.print(Panel(
            Markdown(response.content),
            title=title,
            border_style="blue",
            padding=(1, 2)
        ))
    
    def _display_synthesis(self, synthesis: str):
        """Display the final comprehensive article."""
        if not self.verbose:
            return
        
        self.console.print("\n")
        self.console.print(Panel(
            Markdown(synthesis),
            title="[bold magenta]COMPREHENSIVE ARTICLE - Council Synthesis with Verified Sources[/bold magenta]",
            border_style="magenta",
            padding=(1, 2)
        ))
    
    def quick_discuss(self, topic: str) -> str:
        """Quick single-round discussion (no multi-round debate)."""
        responses = self._conduct_round(topic, None, 1)
        synthesis = self._generate_synthesis(topic, [responses])
        return synthesis


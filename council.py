"""Main LLM Council orchestrator."""
import sys
import os
from typing import List, Optional, Dict
from dataclasses import dataclass, asdict
import json
from datetime import datetime

# Fix Windows console encoding issues with Rich
if sys.platform == "win32":
    os.environ["PYTHONIOENCODING"] = "utf-8"

from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.progress import Progress, SpinnerColumn, TextColumn

from agents import BaseAgent, AgentResponse
from config import Config


@dataclass
class DebateResult:
    """Results from a council debate."""
    topic: str
    rounds: List[List[AgentResponse]]
    synthesis: str
    timestamp: str
    total_tokens: int
    participating_agents: List[str]
    
    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "topic": self.topic,
            "timestamp": self.timestamp,
            "total_tokens": self.total_tokens,
            "participating_agents": self.participating_agents,
            "rounds": [
                [
                    {
                        "agent_name": resp.agent_name,
                        "model": resp.model,
                        "content": resp.content,
                        "tokens_used": resp.tokens_used,
                        "metadata": resp.metadata
                    }
                    for resp in round_responses
                ]
                for round_responses in self.rounds
            ],
            "synthesis": self.synthesis
        }
    
    def save_to_file(self, filename: Optional[str] = None):
        """Save debate results to JSON file."""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"debate_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)
        
        return filename
    
    def save_to_markdown(self, filename: Optional[str] = None) -> str:
        """
        Save debate results as a comprehensive Markdown article.
        
        Args:
            filename: Optional custom filename (without extension)
            
        Returns:
            Path to the saved Markdown file
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"article_{timestamp}.md"
        elif not filename.endswith('.md'):
            filename = f"{filename}.md"
        
        # Build comprehensive markdown article
        markdown_content = self._build_markdown_article()
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        return filename
    
    def _build_markdown_article(self) -> str:
        """Build a comprehensive Markdown article from the debate."""
        lines = []
        
        # Title and metadata
        lines.append(f"# {self.topic}")
        lines.append("")
        lines.append(f"**Generated by LLM Council** - {self.timestamp}")
        lines.append("")
        lines.append(f"**Participating Agents:** {', '.join(self.participating_agents)}")
        lines.append(f"**Total Tokens:** {self.total_tokens:,}")
        lines.append(f"**Debate Rounds:** {len(self.rounds)}")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Add overview diagram
        lines.append("## Debate Overview")
        lines.append("")
        lines.append("```mermaid")
        lines.append("graph LR")
        lines.append(f"    A[Topic:<br/>{self._truncate(self.topic, 40)}] --> B[Multi-Round<br/>Debate]")
        lines.append("")
        
        # Add agents to diagram
        for i, agent in enumerate(self.participating_agents, 1):
            lines.append(f"    B --> C{i}[{agent}]")
        
        lines.append("")
        lines.append("    " + " & ".join([f"C{i}" for i in range(1, len(self.participating_agents)+1)]) + " --> D[Synthesis]")
        lines.append("    D --> E[Comprehensive<br/>Article]")
        lines.append("")
        lines.append("    style E fill:#90EE90")
        lines.append("```")
        lines.append("")
        
        # Add debate process diagram
        lines.append("## Debate Process")
        lines.append("")
        lines.append("```mermaid")
        lines.append("sequenceDiagram")
        lines.append("    participant User")
        lines.append("    participant Council")
        
        # Add agents as participants
        for agent in self.participating_agents[:3]:  # Limit to 3 for readability
            lines.append(f"    participant {agent}")
        
        lines.append("")
        lines.append(f"    User->>Council: {self._truncate(self.topic, 50)}")
        lines.append("")
        
        # Show rounds
        for round_num in range(min(2, len(self.rounds))):  # Show max 2 rounds for readability
            lines.append(f"    Note over Council: Round {round_num + 1}")
            for agent in self.participating_agents[:3]:
                if round_num == 0:
                    lines.append(f"    Council->>+{agent}: Provide analysis with sources")
                    lines.append(f"    {agent}-->>-Council: Analysis + Citations")
                else:
                    lines.append(f"    Council->>+{agent}: Validate sources & cross-check")
                    lines.append(f"    {agent}-->>-Council: Validation + New evidence")
            lines.append("")
        
        lines.append("    Council->>Council: Generate comprehensive article")
        lines.append("    Council-->>User: Final article with verified sources")
        lines.append("```")
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Round summaries
        lines.append("## Debate Rounds Summary")
        lines.append("")
        
        for round_num, round_responses in enumerate(self.rounds, 1):
            lines.append(f"### Round {round_num}: {self._get_round_title(round_num)}")
            lines.append("")
            
            for response in round_responses:
                lines.append(f"#### {response.agent_name}")
                if response.tokens_used:
                    lines.append(f"*Tokens: {response.tokens_used}, Model: {response.model}*")
                lines.append("")
                
                # Add response content (truncated if very long)
                content = response.content
                if len(content) > 2000:
                    lines.append(f"{content[:2000]}...")
                    lines.append("")
                    lines.append(f"*[Response truncated - see full content in JSON file]*")
                else:
                    lines.append(content)
                
                lines.append("")
                lines.append("---")
                lines.append("")
        
        # Comprehensive synthesis (main article)
        lines.append("## Comprehensive Synthesis Article")
        lines.append("")
        lines.append(self.synthesis)
        lines.append("")
        
        # Add statistics diagram
        lines.append("---")
        lines.append("")
        lines.append("## Debate Statistics")
        lines.append("")
        lines.append("```mermaid")
        lines.append("pie title Token Distribution by Agent")
        
        # Calculate token distribution
        for agent_name in self.participating_agents:
            agent_tokens = sum(
                resp.tokens_used or 0 
                for round_responses in self.rounds 
                for resp in round_responses 
                if resp.agent_name == agent_name
            )
            lines.append(f'    "{agent_name}" : {agent_tokens}')
        
        lines.append("```")
        lines.append("")
        
        # Add metadata table
        lines.append("| Metric | Value |")
        lines.append("|--------|-------|")
        lines.append(f"| Total Rounds | {len(self.rounds)} |")
        lines.append(f"| Total Agents | {len(self.participating_agents)} |")
        lines.append(f"| Total Tokens | {self.total_tokens:,} |")
        lines.append(f"| Avg Tokens/Round | {self.total_tokens // len(self.rounds):,} |")
        
        # Count total responses
        total_responses = sum(len(round_responses) for round_responses in self.rounds)
        lines.append(f"| Total Responses | {total_responses} |")
        lines.append(f"| Avg Tokens/Response | {self.total_tokens // total_responses:,} |")
        lines.append("")
        
        # Footer
        lines.append("---")
        lines.append("")
        lines.append("*Generated by [LLM Council](https://github.com/jaafar-benabderrazak/llm-council) - Multi-Agent AI Research Framework*")
        lines.append("")
        lines.append("**Research Mode Features:**")
        lines.append("- ✅ Source citations and validation")
        lines.append("- ✅ Multi-agent cross-checking")
        lines.append("- ✅ Common misconceptions addressed")
        lines.append("- ✅ Technical depth and specifications")
        lines.append("- ✅ Verified references with credibility ratings")
        lines.append("")
        
        return "\n".join(lines)
    
    def _truncate(self, text: str, max_length: int) -> str:
        """Truncate text for diagram labels."""
        text = text.strip().replace("\n", " ")
        if len(text) <= max_length:
            return text
        return text[:max_length-3] + "..."
    
    def _get_round_title(self, round_num: int) -> str:
        """Get descriptive title for round."""
        if round_num == 1:
            return "Initial Analysis with Citations"
        elif round_num == 2:
            return "Source Validation & Cross-Checking"
        elif round_num == 3:
            return "Deep Dive & Refinement"
        else:
            return f"Continued Analysis (Round {round_num})"


class LLMCouncil:
    """Orchestrates multi-agent debates between different LLMs."""
    
    def __init__(self, agents: List[BaseAgent], verbose: bool = True):
        """
        Initialize the LLM Council.
        
        Args:
            agents: List of agents to participate in debates
            verbose: Whether to print progress information
        """
        self.agents = agents
        self.verbose = verbose
        if verbose:
            # Use legacy_windows=False to avoid encoding issues on Windows
            self.console = Console(legacy_windows=False) if sys.platform == "win32" else Console()
        else:
            self.console = None
    
    def debate(
        self, 
        topic: str, 
        rounds: int = 3,
        save_results: bool = True,
        save_markdown: bool = True
    ) -> DebateResult:
        """
        Conduct a multi-round debate on a topic.
        
        Args:
            topic: The topic to debate
            rounds: Number of debate rounds
            save_results: Whether to save results to JSON file
            save_markdown: Whether to save comprehensive article as Markdown
            
        Returns:
            DebateResult containing all responses and synthesis
        """
        if self.verbose:
            self.console.print(Panel.fit(
                f"[bold cyan]LLM Council Debate[/bold cyan]\n\n"
                f"[yellow]Topic:[/yellow] {topic}\n"
                f"[yellow]Rounds:[/yellow] {rounds}\n"
                f"[yellow]Participants:[/yellow] {', '.join([a.name for a in self.agents])}",
                border_style="cyan"
            ))
        
        all_rounds = []
        context = None
        total_tokens = 0
        
        # Conduct debate rounds
        for round_num in range(rounds):
            if self.verbose:
                self.console.print(f"\n[bold green]=== Round {round_num + 1}/{rounds} ===[/bold green]\n")
            
            round_responses = self._conduct_round(topic, context, round_num + 1)
            all_rounds.append(round_responses)
            context = round_responses
            
            # Calculate tokens
            for response in round_responses:
                if response.tokens_used:
                    total_tokens += response.tokens_used
        
        # Generate synthesis
        if self.verbose:
            self.console.print("\n[bold magenta]=== Generating Synthesis ===[/bold magenta]\n")
        
        synthesis = self._generate_synthesis(topic, all_rounds)
        
        # Create result
        result = DebateResult(
            topic=topic,
            rounds=all_rounds,
            synthesis=synthesis,
            timestamp=datetime.now().isoformat(),
            total_tokens=total_tokens,
            participating_agents=[agent.name for agent in self.agents]
        )
        
        # Save if requested
        if save_results:
            json_filename = result.save_to_file()
            if self.verbose:
                self.console.print(f"\n[dim]JSON results saved to: {json_filename}[/dim]")
        
        if save_markdown:
            md_filename = result.save_to_markdown()
            if self.verbose:
                self.console.print(f"[dim]Markdown article saved to: {md_filename}[/dim]")
        
        if self.verbose:
            self.console.print("\n[bold green]Debate Complete![/bold green]")
            self._display_synthesis(synthesis)
        
        return result
    
    def _conduct_round(
        self, 
        topic: str, 
        context: Optional[List[AgentResponse]], 
        round_num: int
    ) -> List[AgentResponse]:
        """Conduct a single debate round with all agents."""
        responses = []
        
        # Build the prompt based on round number
        if round_num == 1:
            prompt = f"""Discuss the following topic and provide your initial perspective with proper citations and sources:

TOPIC: {topic}

Remember to:
- Provide technical depth and specific examples
- Cite authoritative sources (research papers, documentation, official resources)
- Include URLs or proper citations
- Be precise with technical specifications"""
        else:
            prompt = f"""Review the previous responses and provide your critical analysis:

TOPIC: {topic}

Your tasks for Round {round_num}:
- VALIDATE sources provided by other council members
- CROSS-CHECK facts and identify any errors
- CHALLENGE weak arguments with counter-evidence
- BUILD ON strong points with additional sources
- ADDRESS common misconceptions
- PROVIDE new insights with proper citations"""
        
        for agent in self.agents:
            if self.verbose:
                self.console.print(f"[cyan]{agent.name} thinking...[/cyan]")
                response = agent.generate_response(prompt, context, round_num)
                self._display_response(response)
            else:
                response = agent.generate_response(prompt, context, round_num)
            
            responses.append(response)
            
            # Update context for next agent in this round
            if context is None:
                context = [response]
            else:
                context = context + [response]
        
        return responses
    
    def _generate_synthesis(
        self, 
        topic: str, 
        all_rounds: List[List[AgentResponse]]
    ) -> str:
        """Generate a comprehensive academic-style article from all debate rounds."""
        # Use the first agent to synthesize
        synthesizer = self.agents[0]
        
        # Build comprehensive context
        all_responses = []
        for round_num, round_responses in enumerate(all_rounds, 1):
            for response in round_responses:
                all_responses.append(response)
        
        synthesis_prompt = f"""Based on the council's multi-round discussion on: "{topic}"

You must now write a COMPREHENSIVE ACADEMIC-STYLE ARTICLE that:

1. **EXECUTIVE SUMMARY**
   - Brief overview of the topic and key findings
   - Main conclusions (2-3 sentences)

2. **INTRODUCTION**
   - Context and importance of the topic
   - Key questions addressed
   - Scope of the analysis

3. **DETAILED ANALYSIS**
   - Synthesize all perspectives presented
   - Include technical details, specifications, and data points
   - Organize by themes or sub-topics
   - Use headings and subheadings

4. **SOURCE VALIDATION & CROSS-CHECKING**
   - Evaluate the quality and reliability of sources cited
   - List VERIFIED sources (URLs, papers, documentation)
   - Note any conflicting sources or disputed claims
   - Rate source credibility (High/Medium/Low with justification)

5. **CONSENSUS & DISAGREEMENTS**
   - Points of strong agreement across council members
   - Areas of disagreement with competing evidence
   - Nuanced perspectives that warrant consideration

6. **COMMON MISCONCEPTIONS ADDRESSED**
   - Identify and correct common misunderstandings about this topic
   - Explain why these misconceptions are wrong
   - Provide correct information with sources

7. **TECHNICAL DEEP DIVE**
   - Detailed technical specifications, benchmarks, or data
   - Implementation considerations
   - Performance characteristics (if applicable)
   - Trade-offs and limitations

8. **GAPS & LIMITATIONS**
   - What the council couldn't fully address
   - Areas requiring further research
   - Acknowledged uncertainties

9. **ACTIONABLE RECOMMENDATIONS**
   - Concrete, specific recommendations
   - Prioritized by importance and feasibility
   - Context-dependent guidance (when to do X vs Y)

10. **VERIFIED REFERENCES & RESOURCES**
    - Complete list of all cited sources
    - Format: [Title/Description] - [URL or Citation] - [Credibility Rating]
    - Organize by category (Research Papers, Documentation, Tools, etc.)

11. **CONCLUSION**
    - Summary of findings
    - Final verdict or recommendations
    - Future outlook

**FORMAT REQUIREMENTS:**
- Use Markdown formatting with proper headers (##, ###)
- Include bullet points and numbered lists where appropriate
- Make it readable, comprehensive, and academically rigorous
- Minimum 1000 words for complex topics
- Every major claim should reference a source from the debate
- Be thorough, objective, and balanced

Generate the complete article now:"""

        if self.verbose:
            self.console.print("[magenta]Generating comprehensive article with verified sources...[/magenta]")
            synthesis_response = synthesizer.generate_response(
                synthesis_prompt, 
                all_responses,
                round_num=999  # Special round number for synthesis
            )
        else:
            synthesis_response = synthesizer.generate_response(
                synthesis_prompt, 
                all_responses,
                round_num=999
            )
        
        return synthesis_response.content
    
    def _display_response(self, response: AgentResponse):
        """Display an agent response in the console."""
        if not self.verbose:
            return
        
        title = f"[bold]{response.agent_name}[/bold] ({response.model})"
        if response.tokens_used:
            title += f" - {response.tokens_used} tokens"
        
        self.console.print(Panel(
            Markdown(response.content),
            title=title,
            border_style="blue",
            padding=(1, 2)
        ))
    
    def _display_synthesis(self, synthesis: str):
        """Display the final comprehensive article."""
        if not self.verbose:
            return
        
        self.console.print("\n")
        self.console.print(Panel(
            Markdown(synthesis),
            title="[bold magenta]COMPREHENSIVE ARTICLE - Council Synthesis with Verified Sources[/bold magenta]",
            border_style="magenta",
            padding=(1, 2)
        ))
    
    def quick_discuss(self, topic: str) -> str:
        """Quick single-round discussion (no multi-round debate)."""
        responses = self._conduct_round(topic, None, 1)
        synthesis = self._generate_synthesis(topic, [responses])
        return synthesis

